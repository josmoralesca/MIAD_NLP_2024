{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21995</td>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13995</td>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17941</td>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12493</td>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7994</td>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  \\\n",
       "7    21995  2014     6480        0           0            0         1   \n",
       "11   13995  2014    39972        0           0            0         0   \n",
       "167  17941  2016    18989        0           0            0         0   \n",
       "225  12493  2014    51330        0           0            0         1   \n",
       "270   7994  2007   116065        0           1            0         0   \n",
       "\n",
       "     M_CamryLE  M_CamrySE  M_CamryXLE  \n",
       "7            0          0           0  \n",
       "11           1          0           0  \n",
       "167          0          1           0  \n",
       "225          0          0           0  \n",
       "270          0          0           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Lectura de la información de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
    "\n",
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data = data.drop(['Model'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['Price']\n",
    "X = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el RMSE y MAE del modelo en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de prueba: 1686.3982663440495\n",
      "MAE en el conjunto de prueba: 1243.8200219222183\n"
     ]
    }
   ],
   "source": [
    "# Celda 1\n",
    "# Definición de la función para calcular el error cuadrático medio (RMSE)\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "\n",
    "# Definición de la función para calcular el error absoluto medio (MAE)\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "# Definición del nodo del árbol\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature  # Índice de la característica para dividir\n",
    "        self.threshold = threshold  # Valor de umbral para dividir\n",
    "        self.left = left  # Subárbol izquierdo\n",
    "        self.right = right  # Subárbol derecho\n",
    "        self.value = value  # Valor de predicción en las hojas\n",
    "\n",
    "# Definición del árbol de regresión\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "    # Función para ajustar el árbol a los datos de entrenamiento\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    # Función recursiva para construir el árbol\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # Condiciones de parada\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or n_labels == 1 or n_samples < self.min_samples_split:\n",
    "            return Node(value=np.mean(y))\n",
    "\n",
    "        # Encontrar la mejor división\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_loss = np.inf\n",
    "        for feature in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature] < threshold\n",
    "                y_left = y[left_indices]\n",
    "                y_right = y[~left_indices]\n",
    "                loss = len(y_left) * np.var(y_left) + len(y_right) * np.var(y_right)\n",
    "                if loss < best_loss:\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_loss = loss\n",
    "\n",
    "        # Dividir los datos\n",
    "        left_indices = X[:, best_feature] < best_threshold\n",
    "        X_left, y_left = X[left_indices], y[left_indices]\n",
    "        X_right, y_right = X[~left_indices], y[~left_indices]\n",
    "\n",
    "        # Recursión para construir los subárboles\n",
    "        left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "        right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "\n",
    "        return Node(feature=best_feature, threshold=best_threshold, left=left, right=right)\n",
    "\n",
    "    # Función para hacer predicciones\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_value(x, self.root) for x in X])\n",
    "\n",
    "    # Función auxiliar para predecir el valor de un solo ejemplo\n",
    "    def _predict_value(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] < node.threshold:\n",
    "            return self._predict_value(x, node.left)\n",
    "        else:\n",
    "            return self._predict_value(x, node.right)\n",
    "\n",
    "# Crear y entrenar el árbol de regresión\n",
    "tree_reg = DecisionTreeRegressor(max_depth=6)\n",
    "tree_reg.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = tree_reg.predict(X_test.values)\n",
    "\n",
    "# Calcular RMSE y MAE\n",
    "rmse_score = rmse(y_test.values, y_pred)\n",
    "mae_score = mae(y_test.values, y_pred)\n",
    "\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse_score)\n",
    "print(\"MAE en el conjunto de prueba:\", mae_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de regresión y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de prueba: 1599.6185696638138\n",
      "MAE en el conjunto de prueba: 1179.2498831616103\n"
     ]
    }
   ],
   "source": [
    "# Celda 2\n",
    "# Definición del modelo Bagging\n",
    "class BaggingRegressor:\n",
    "    def __init__(self, n_estimators=10, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.estimators = []\n",
    "\n",
    "    # Función para entrenar el modelo\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Muestreo aleatorio con reemplazo\n",
    "            indices = np.random.choice(len(X), size=len(X), replace=True)\n",
    "            X_bootstrap, y_bootstrap = X[indices], y[indices]\n",
    "            # Crear y entrenar un árbol de regresión\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.estimators.append(tree)\n",
    "\n",
    "    # Función para hacer predicciones\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.estimators])\n",
    "        return np.mean(predictions, axis=0)\n",
    "\n",
    "# Crear y entrenar el modelo Bagging\n",
    "bagging_reg = BaggingRegressor(n_estimators=10, max_depth=6)\n",
    "bagging_reg.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = bagging_reg.predict(X_test.values)\n",
    "\n",
    "# Calcular RMSE y MAE\n",
    "rmse_score = rmse(y_test.values, y_pred)\n",
    "mae_score = mae(y_test.values, y_pred)\n",
    "\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse_score)\n",
    "print(\"MAE en el conjunto de prueba:\", mae_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de bagging muestra una mejora en ambos indicadores de rendimiento en comparación con el árbol de decisión individual. El RMSE y el MAE son más bajos en el modelo de bagging, lo que indica que este modelo tiene una mejor capacidad para hacer predicciones más precisas en el conjunto de prueba.\n",
    "\n",
    "Ventajas del modelo de bagging:\n",
    "\n",
    "- Reducción de la varianza: Al promediar las predicciones de múltiples árboles, el modelo de bagging tiende a reducir la varianza, lo que puede mejorar la capacidad de generalización del modelo y reducir el riesgo de sobreajuste.\n",
    "- Mayor estabilidad: Al entrenar múltiples árboles en muestras aleatorias del conjunto de entrenamiento, el modelo de bagging tiende a ser más robusto y estable que un solo árbol de decisión.\n",
    "\n",
    "Desventajas del modelo de bagging:\n",
    "\n",
    "- Mayor complejidad: Debido a que implica entrenar múltiples árboles y combinar sus predicciones, el modelo de bagging puede ser más complejo y requerir más recursos computacionales que un solo árbol de decisión.\n",
    "- Menor interpretabilidad: Al combinar múltiples modelos, la interpretación de cómo se llega a una predicción específica puede ser más complicada en comparación con un solo árbol de decisión.\n",
    "\n",
    "En resumen, el modelo de bagging muestra un mejor rendimiento en términos de precisión de predicción en este caso particular. Sin embargo, debe considerarse que el aumento en la precisión viene a costa de una mayor complejidad y menor interpretabilidad. Dependiendo de las necesidades específicas del problema y las limitaciones de recursos, puede ser preferible utilizar el modelo de bagging sobre un solo árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de regresión y el parámetro `max_features` igual a `log(n_features)` y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de prueba: 1813.0409476471518\n",
      "MAE en el conjunto de prueba: 1353.424136561091\n"
     ]
    }
   ],
   "source": [
    "# Celda 3\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Crear el modelo Bagging\n",
    "n_estimators = 10\n",
    "max_features = int(np.log(X_train.shape[1]))\n",
    "bagging_model = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_features=max_features),\n",
    "                                 n_estimators=n_estimators,\n",
    "                                 random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = bagging_model.predict(X_test)\n",
    "\n",
    "# Calcular RMSE y MAE\n",
    "rmse_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae_score = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse_score)\n",
    "print(\"MAE en el conjunto de prueba:\", mae_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de Bagging implementado sin librería muestra el mejor desempeño en términos de RMSE y MAE en el conjunto de prueba, seguido por el modelo de Árbol de Decisión y luego el modelo de Bagging implementado con sklearn.\n",
    "\n",
    "En este caso particular, el modelo de Bagging implementado sin librería muestra el mejor desempeño, lo que sugiere que la técnica de Bagging puede ser efectiva para mejorar la precisión de las predicciones en este conjunto de datos específico. Sin embargo, se debe tener en cuenta que la implementación manual puede requerir más esfuerzo y conocimientos técnicos en comparación con el uso de librerías como sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para regresión  y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de prueba: 1765.4118259983413\n",
      "MAE en el conjunto de prueba: 1314.4207078056425\n"
     ]
    }
   ],
   "source": [
    "# Celda 4\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Crear el modelo de Random Forest\n",
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calcular RMSE y MAE\n",
    "rmse_score = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae_score = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse_score)\n",
    "print(\"MAE en el conjunto de prueba:\", mae_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo Random Forest muestra un rendimiento intermedio en términos de RMSE y MAE en comparación con los otros modelos evaluados.\n",
    "\n",
    "Ventajas del Random Forest:\n",
    "\n",
    "- Reducción del sobreajuste: Al utilizar múltiples árboles de decisión y combinar sus predicciones, el Random Forest tiende a reducir el sobreajuste en comparación con un solo árbol de decisión.\n",
    "- Mayor precisión: En general, el Random Forest tiende a producir predicciones más precisas que un solo árbol de decisión, como se observa en este análisis comparativo.\n",
    "\n",
    "Desventajas del Random Forest:\n",
    "\n",
    "- Mayor complejidad: El Random Forest puede ser más complejo y requerir más recursos computacionales que un solo árbol de decisión, especialmente cuando se utilizan muchos árboles en el conjunto.\n",
    "- Menor interpretabilidad: Al combinar múltiples modelos, la interpretación de cómo se llega a una predicción específica puede ser más complicada en comparación con un solo árbol de decisión.\n",
    "\n",
    "En este caso particular, el Random Forest tiene un desempeño similar al Bagging implementado con sklearn, pero ligeramente inferior al Bagging sin librería. Sin embargo, el Random Forest sigue siendo una opción sólida para mejorar la precisión de las predicciones en comparación con un solo árbol de decisión. La elección del mejor modelo dependerá de las necesidades específicas del problema, las restricciones de recursos y las preferencias del usuario en términos de interpretabilidad y rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "RMSE en el conjunto de prueba: 1564.2461359342767\n",
      "MAE en el conjunto de prueba: 1147.2014922680428\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 5\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Definir los parámetros a explorar\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# Crear el modelo de Random Forest\n",
    "random_forest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Inicializar la búsqueda en cuadrícula\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Ejecutar la búsqueda en cuadrícula\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores parámetros encontrados\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_random_forest = grid_search.best_estimator_\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_random_forest.predict(X_test)\n",
    "\n",
    "# Calcular RMSE y MAE\n",
    "rmse_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae_score = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse_score)\n",
    "print(\"MAE en el conjunto de prueba:\", mae_score)\n",
    "\n",
    "\n",
    "\n",
    "# Obtener los resultados de la búsqueda en cuadrícula\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Extraer los valores de los parámetros y los puntajes de validación cruzada\n",
    "param_max_depth = results['param_max_depth'].data.astype(np.float32)\n",
    "param_max_features = results['param_max_features'].data\n",
    "param_n_estimators = results['param_n_estimators'].data\n",
    "mean_test_score = np.sqrt(-results['mean_test_score'])\n",
    "\n",
    "# Crear subgráficos para cada parámetro\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Graficar cómo varía el RMSE con respecto a max_depth\n",
    "axs[0].scatter(param_max_depth, mean_test_score)\n",
    "axs[0].set_xlabel('max_depth')\n",
    "axs[0].set_ylabel('RMSE')\n",
    "axs[0].set_title('RMSE vs max_depth')\n",
    "\n",
    "# Graficar cómo varía el RMSE con respecto a max_features\n",
    "axs[1].scatter(param_max_features, mean_test_score)\n",
    "axs[1].set_xlabel('max_features')\n",
    "axs[1].set_ylabel('RMSE')\n",
    "axs[1].set_title('RMSE vs max_features')\n",
    "\n",
    "# Graficar cómo varía el RMSE con respecto a n_estimators\n",
    "axs[2].scatter(param_n_estimators, mean_test_score)\n",
    "axs[2].set_xlabel('n_estimators')\n",
    "axs[2].set_ylabel('RMSE')\n",
    "axs[2].set_title('RMSE vs n_estimators')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desempeño del Modelo:\n",
    "El modelo Random Forest calibrado muestra un mejor desempeño en términos de RMSE (1564.25) y MAE (1147.20) en comparación con los otros modelos evaluados.\n",
    "\n",
    "Efecto de cada Parámetro:\n",
    "\n",
    "max_depth:\n",
    "- Controla la profundidad máxima de los árboles en el bosque.\n",
    "- Un valor bajo puede resultar en underfitting, mientras que uno alto puede causar overfitting.\n",
    "- Un valor óptimo encontrado fue de 10, permitiendo suficiente complejidad para capturar patrones en los datos sin sobreajuste.\n",
    "\n",
    "max_features:\n",
    "- Controla la cantidad de características consideradas al dividir cada nodo del árbol.\n",
    "- Un valor óptimo fue 'sqrt', que utiliza la raíz cuadrada del número total de características en cada división.\n",
    "- Esto proporciona una buena variabilidad en las características consideradas en cada árbol, mejorando la generalización del modelo.\n",
    "\n",
    "n_estimators:\n",
    "- Determina la cantidad de árboles en el bosque.\n",
    "- Un mayor número de árboles puede mejorar la capacidad de generalización del modelo, pero también aumenta el costo computacional.\n",
    "- Un valor óptimo fue de 200, lo que proporciona un buen equilibrio entre precisión y eficiencia.\n",
    "\n",
    "En conjunto, la calibración de los parámetros permitió mejorar significativamente el desempeño del modelo Random Forest, logrando una mejor capacidad de generalización y reducción del error de predicción en comparación con los modelos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de regresión con la librería sklearn y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de prueba: 1605.2355199928948\n",
      "MAE en el conjunto de prueba: 1185.2272991506386\n"
     ]
    }
   ],
   "source": [
    "# Celda 6\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Crear y entrenar el modelo XGBoost de regresión\n",
    "xgb_reg = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Mostrar métricas de evaluación\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse)\n",
    "print(\"MAE en el conjunto de prueba:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis Comparativo del Desempeño del Modelo XGBoost:\n",
    "\n",
    "El modelo XGBoost muestra un mejor desempeño en términos de RMSE y MAE en comparación con los modelos base, incluidos el Árbol de Decisión, Bagging y Random Forest. Esto sugiere que XGBoost es capaz de capturar patrones más complejos en los datos y hacer predicciones más precisas.\n",
    "\n",
    "Las ventajas de XGBoost incluyen su capacidad para manejar automáticamente la regularización, lo que ayuda a prevenir el sobreajuste y mejorar la generalización del modelo. Además, XGBoost ofrece buen rendimiento en conjuntos de datos grandes, escalabilidad y paralelización, lo que lo hace adecuado para problemas con grandes volúmenes de datos. También proporciona soporte para características faltantes y tiene soporte integrado para manejo de variables categóricas, lo que facilita el tratamiento de diferentes tipos de datos.\n",
    "\n",
    "En resumen, el modelo XGBoost es una opción sólida para problemas de regresión debido a su capacidad para producir resultados precisos y su capacidad para manejar una variedad de desafíos de modelado de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] END ..colsample_bytree=0.5, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=0.5, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=0.5, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=0.5, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=0.5, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.5, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.5, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.5, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.5, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.5, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.5, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.5, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.5, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.5, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.5, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.5, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.2, learning_rate=0.2; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.2; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.2, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.2, learning_rate=0.2; total time=   0.0s\n",
      "Mejores parámetros: {'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1}\n",
      "RMSE en el conjunto de prueba: 1544.8340760527965\n",
      "MAE en el conjunto de prueba: 1134.5761896358076\n"
     ]
    }
   ],
   "source": [
    "# Celda 7\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "# Crear el modelo XGBoost\n",
    "xgb_reg = XGBRegressor()\n",
    "\n",
    "# Configurar la búsqueda en la cuadrícula con validación cruzada\n",
    "grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, \n",
    "                           scoring='neg_mean_squared_error', cv=5, verbose=2)\n",
    "\n",
    "# Realizar la búsqueda en la cuadrícula para encontrar los mejores parámetros\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores parámetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "\n",
    "# Crear un nuevo modelo XGBoost con los mejores parámetros encontrados\n",
    "best_xgb_reg = XGBRegressor(**best_params)\n",
    "\n",
    "# Entrenar el modelo con los mejores parámetros\n",
    "best_xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_xgb_reg.predict(X_test)\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Mostrar métricas de evaluación\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse)\n",
    "print(\"MAE en el conjunto de prueba:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis Comparativo del Desempeño del Modelo XGBoost Calibrado:\n",
    "\n",
    "El modelo XGBoost calibrado muestra un mejor desempeño en términos de RMSE y MAE en comparación con los modelos base y el modelo XGBoost no calibrado. Esto sugiere que la calibración de los parámetros del modelo XGBoost ha mejorado su capacidad predictiva.\n",
    "\n",
    "Los parámetros calibrados son:\n",
    "- learning_rate: 0.1\n",
    "- gamma: 0\n",
    "- colsample_bytree: 0.5\n",
    "\n",
    "El learning_rate controla la contribución de cada árbol en el conjunto. Un valor más bajo generalmente conduce a una mejor generalización, pero requiere más árboles en el conjunto. El parámetro gamma controla la reducción de la pérdida de información al hacer una partición en un nodo del árbol. Un valor más alto lleva a una mayor regularización. colsample_bytree determina la proporción de características utilizadas en cada árbol. Un valor más bajo puede ayudar a reducir el sobreajuste.\n",
    "\n",
    "En este caso, los parámetros calibrados han resultado en un modelo XGBoost más generalizable, con menor error tanto en el conjunto de prueba, lo que indica una mejor capacidad para hacer predicciones precisas sobre datos no vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando los resultados obtenidos de los diferentes modelos (Random Forest y XGBoost):\n",
    "\n",
    "Random Forest (Calibrado):\n",
    "- RMSE en el conjunto de prueba: 1564.25\n",
    "- MAE en el conjunto de prueba: 1147.20\n",
    "\n",
    "XGBoost (Calibrado):\n",
    "- RMSE en el conjunto de prueba: 1544.83\n",
    "- MAE en el conjunto de prueba: 1134.58\n",
    "\n",
    "\n",
    "Ventajas de XGBoost (Calibrado):\n",
    "- Menor RMSE y MAE en comparación con Random Forest (Calibrado), lo que indica una mejor capacidad de predicción.\n",
    "- El modelo XGBoost tiende a funcionar bien incluso en conjuntos de datos más pequeños.\n",
    "- Puede manejar una variedad de tipos de datos, incluidos datos faltantes y categóricos, sin necesidad de preprocesamiento adicional.\n",
    "- Menos propenso al sobreajuste debido a la regularización incorporada y la capacidad de detener el entrenamiento temprano si no mejora la métrica de evaluación.\n",
    "\n",
    "Desventajas de Random Forest (Calibrado):\n",
    "- RMSE y MAE ligeramente más altos en comparación con XGBoost (Calibrado).\n",
    "- Puede ser menos eficiente en la predicción de conjuntos de datos más grandes y complejos en comparación con XGBoost.\n",
    "\n",
    "En resumen, el modelo XGBoost (Calibrado) es preferible debido a su mejor desempeño en la predicción y su capacidad para manejar una variedad de datos, incluidos los faltantes y categóricos, sin necesidad de preprocesamiento adicional. Aunque ambos modelos son efectivos, XGBoost generalmente supera a Random Forest en términos de precisión y flexibilidad en diferentes tipos de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
